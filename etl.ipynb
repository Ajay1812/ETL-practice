{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-09 12:51:06--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2707 (2.6K) [application/zip]\n",
      "Saving to: â€˜source.zipâ€™\n",
      "\n",
      "source.zip          100%[===================>]   2.64K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-01-09 12:51:08 (861 MB/s) - â€˜source.zipâ€™ saved [2707/2707]\n",
      "\n",
      "Archive:  source.zip\n",
      "  inflating: source3.json            \n",
      "  inflating: source1.csv             \n",
      "  inflating: source2.csv             \n",
      "  inflating: source3.csv             \n",
      "  inflating: source1.json            \n",
      "  inflating: source2.json            \n",
      "  inflating: source1.xml             \n",
      "  inflating: source2.xml             \n",
      "  inflating: source3.xml             \n"
     ]
    }
   ],
   "source": [
    "!wget \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/source.zip\"\n",
    "!unzip \"source.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed_data\n",
      "     name  height  weight\n",
      "0    alex    1.67   51.25\n",
      "1    ajay    1.82   61.91\n",
      "2   alice    1.76   69.41\n",
      "3    ravi    1.73   64.56\n",
      "4     joe    1.72   65.45\n",
      "5    alex    1.67   51.25\n",
      "6    ajay    1.82   61.91\n",
      "7   alice    1.76   69.41\n",
      "8    ravi    1.73   64.56\n",
      "9     joe    1.72   65.45\n",
      "10   alex    1.67   51.25\n",
      "11   ajay    1.82   61.91\n",
      "12  alice    1.76   69.41\n",
      "13   ravi    1.73   64.56\n",
      "14    joe    1.72   65.45\n",
      "15   jack    1.74   55.93\n",
      "16    tom    1.77   64.18\n",
      "17  tracy    1.78   61.90\n",
      "18   john    1.72   50.97\n",
      "19   jack    1.74   55.93\n",
      "20    tom    1.77   64.18\n",
      "21  tracy    1.78   61.90\n",
      "22   john    1.72   50.97\n",
      "23   jack    1.74   55.93\n",
      "24    tom    1.77   64.18\n",
      "25  tracy    1.78   61.90\n",
      "26   john    1.72   50.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sh/243scdkn0fb479j7tgjqgmt00000gn/T/ipykernel_24720/3404526281.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "\n",
    "log_file = \"log_file.txt\"\n",
    "target_file = \"transformed_data.csv\"\n",
    "\n",
    "def extract_from_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "def extract_from_json(file):\n",
    "    df = pd.read_json(file, lines= True)\n",
    "    return df\n",
    "\n",
    "def extract_from_xml(file):\n",
    "    df = pd.DataFrame(columns= ['name','height','weight'])\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    for person in root:\n",
    "        name = person.find('name').text\n",
    "        height = person.find('height').text\n",
    "        weight = person.find('weight').text\n",
    "        df = pd.concat([df, pd.DataFrame([{\"name\":name,\"height\":height, \"weight\": weight}])], ignore_index = True)\n",
    "        # print(df)\n",
    "\n",
    "# extract_from_xml('source1.xml')\n",
    "\n",
    "def extract():\n",
    "    extracted_data = pd.DataFrame(columns= ['name','height','weight'])\n",
    "    for csvfile in glob.glob('*.csv'):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_csv(csvfile))], ignore_index=True)\n",
    "    for jsonfile in glob.glob('*.json'):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_json(jsonfile))], ignore_index=True)\n",
    "    for xmlfile in glob.glob('*.xml'):\n",
    "        extracted_data = pd.concat([extracted_data, pd.DataFrame(extract_from_xml(xmlfile))], ignore_index=True)\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "\n",
    "# Transformation\n",
    "def transform(data):\n",
    "    data['height'] = round(data.height * 0.0254,2)\n",
    "    data['weight'] = round(data.weight * 0.45359237,2)\n",
    "    return data\n",
    "\n",
    "# Loading and logging\n",
    "\n",
    "def load_data(target_file, transformed_data):\n",
    "    transformed_data.to_csv(target_file)\n",
    "\n",
    "def logging(message):\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S'\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(timestamp_format)\n",
    "    with open (log_file, 'a') as f:\n",
    "        f.write(timestamp + ',' + message + '\\n')\n",
    "\n",
    "logging('ETL Job Started ðŸ¤ ')\n",
    "\n",
    "logging(\"Extract Phase Started\")\n",
    "extracted_data = extract()\n",
    "\n",
    "logging(\"Extract Phase Ended\")\n",
    "\n",
    "logging('Transform Phase Started')\n",
    "transformed_data = transform(extracted_data)\n",
    "print(\"transformed_data\")\n",
    "print(transformed_data)\n",
    "logging('Transform Phase Ended')\n",
    "\n",
    "logging('Load Phase Started')\n",
    "load_data(target_file, transformed_data)\n",
    "logging('Load Phase Ended')\n",
    "\n",
    "logging(\"ETL Job Ended\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de-venv",
   "language": "python",
   "name": "de-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
